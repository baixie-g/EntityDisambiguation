#!/usr/bin/env python3
"""
æµ‹è¯•Sigmoidå½’ä¸€åŒ–æ•ˆæœ
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

import numpy as np
from services.disambiguation import DisambiguationService

def test_sigmoid_normalization():
    """æµ‹è¯•sigmoidå½’ä¸€åŒ–æ•ˆæœ"""
    print("=" * 80)
    print("Sigmoidå½’ä¸€åŒ–æ•ˆæœæµ‹è¯•")
    print("=" * 80)
    
    # åˆ›å»ºæ¶ˆæ­§æœåŠ¡å®ä¾‹
    service = DisambiguationService()
    
    # åŸºäºå®é™…æµ‹è¯•ç»“æœçš„CrossEncoderåŸå§‹å¾—åˆ†
    test_scores = [
        ("å®Œå…¨ç›¸åŒçš„æ–‡æœ¬", 7.7106),
        ("ç³–å°¿ç—… vs ç³–å°¿ç—…", 4.9174),
        ("ç³–å°¿ç—… vs ç³–å°¿", 3.3470),
        ("ç³–å°¿ç—… vs é«˜è¡€å‹", 0.1097),
        ("ç³–å°¿ç—… vs diabetes", -6.5320),
        ("æœºæ¢°ä¸åŠ¨åŠ›å·¥ç¨‹ vs å°æ", -5.4104),
        ("ç©ºæ–‡æœ¬", -3.3430),
    ]
    
    print("ğŸ“Š Sigmoidå½’ä¸€åŒ–æ•ˆæœ:")
    print("-" * 60)
    print(f"{'æµ‹è¯•ç”¨ä¾‹':<25} {'åŸå§‹å¾—åˆ†':<12} {'Sigmoidå½’ä¸€åŒ–':<15} {'è¯´æ˜'}")
    print("-" * 60)
    
    normalized_scores = []
    for test_case, original_score in test_scores:
        normalized_score = service.normalize_crossencoder_score(original_score)
        normalized_scores.append(normalized_score)
        
        # åˆ¤æ–­å¾—åˆ†ç±»å‹
        if original_score > 5.0:
            description = "å®Œå…¨åŒ¹é…"
        elif original_score > 2.0:
            description = "é«˜ç›¸å…³"
        elif original_score > 0.0:
            description = "ä¸­ç­‰ç›¸å…³"
        elif original_score > -2.0:
            description = "ä½ç›¸å…³"
        else:
            description = "ä¸ç›¸å…³"
        
        print(f"{test_case:<25} {original_score:<12.4f} {normalized_score:<15.4f} {description}")
    
    print("-" * 60)
    
    # ç»Ÿè®¡ä¿¡æ¯
    min_normalized = min(normalized_scores)
    max_normalized = max(normalized_scores)
    avg_normalized = sum(normalized_scores) / len(normalized_scores)
    
    print(f"\nğŸ“ˆ å½’ä¸€åŒ–ç»Ÿè®¡:")
    print(f"  æœ€å°å€¼: {min_normalized:.4f}")
    print(f"  æœ€å¤§å€¼: {max_normalized:.4f}")
    print(f"  å¹³å‡å€¼: {avg_normalized:.4f}")
    print(f"  å¾—åˆ†èŒƒå›´: {min_normalized:.4f} - {max_normalized:.4f}")
    
    # éªŒè¯å½’ä¸€åŒ–æ•ˆæœ
    print(f"\nâœ… å½’ä¸€åŒ–éªŒè¯:")
    print(f"  - æ‰€æœ‰å¾—åˆ†éƒ½åœ¨0.0-1.0èŒƒå›´å†…: {min_normalized >= 0.0 and max_normalized <= 1.0}")
    print(f"  - è´Ÿåˆ†è¢«æ­£ç¡®æ˜ å°„: {min_normalized > 0.0}")
    print(f"  - é«˜åˆ†è¢«æ­£ç¡®æ˜ å°„: {max_normalized < 1.0}")
    
    return normalized_scores

def test_weighted_scores():
    """æµ‹è¯•ä¿®æ­£åçš„åŠ æƒå¾—åˆ†"""
    print("\n" + "=" * 80)
    print("ä¿®æ­£ååŠ æƒå¾—åˆ†æµ‹è¯•")
    print("=" * 80)
    
    service = DisambiguationService()
    
    # æµ‹è¯•ç”¨ä¾‹
    test_cases = [
        {
            "name": "å®Œå…¨åŒ¹é…",
            "bge": 1.0,
            "cross_original": 7.7106,
            "fuzz": 1.0,
            "levenshtein": 1.0
        },
        {
            "name": "é«˜åŒ¹é…",
            "bge": 0.8,
            "cross_original": 4.9174,
            "fuzz": 0.9,
            "levenshtein": 0.8
        },
        {
            "name": "ä¸­ç­‰åŒ¹é…",
            "bge": 0.6,
            "cross_original": 3.3470,
            "fuzz": 0.7,
            "levenshtein": 0.6
        },
        {
            "name": "ä½åŒ¹é…",
            "bge": 0.3,
            "cross_original": 0.1097,
            "fuzz": 0.4,
            "levenshtein": 0.3
        },
        {
            "name": "ä¸åŒ¹é…",
            "bge": 0.1,
            "cross_original": -6.5320,
            "fuzz": 0.1,
            "levenshtein": 0.1
        }
    ]
    
    # æƒé‡é…ç½®
    weights = {
        "bge": 0.4,
        "cross": 0.3,
        "fuzz": 0.2,
        "levenshtein": 0.1
    }
    
    print("ğŸ“Š æƒé‡é…ç½®:")
    for model, weight in weights.items():
        print(f"  {model}: {weight}")
    
    print(f"\nğŸ§® ä¿®æ­£ååŠ æƒå¾—åˆ†è®¡ç®—:")
    print("  åŠ æƒå¾—åˆ† = BGEÃ—0.4 + CrossEncoder(sigmoidå½’ä¸€åŒ–)Ã—0.3 + FuzzÃ—0.2 + LevenshteinÃ—0.1")
    
    print(f"\n{'åŒ¹é…æƒ…å†µ':<12} {'BGE':<8} {'Cross(åŸå§‹)':<12} {'Cross(å½’ä¸€åŒ–)':<12} {'Fuzz':<8} {'Levenshtein':<12} {'åŠ æƒå¾—åˆ†':<12} {'çŠ¶æ€'}")
    print("-" * 100)
    
    for case in test_cases:
        # è®¡ç®—sigmoidå½’ä¸€åŒ–çš„CrossEncoderå¾—åˆ†
        cross_normalized = service.normalize_crossencoder_score(case['cross_original'])
        
        # è®¡ç®—åŠ æƒå¾—åˆ†
        weighted_score = (
            case['bge'] * weights['bge'] +
            cross_normalized * weights['cross'] +
            case['fuzz'] * weights['fuzz'] +
            case['levenshtein'] * weights['levenshtein']
        )
        
        # åˆ¤æ–­çŠ¶æ€
        if weighted_score > 1.0:
            status = "âŒ è¶…è¿‡1.0"
        elif weighted_score < 0.0:
            status = "âŒ è´Ÿå€¼"
        else:
            status = "âœ… æ­£å¸¸"
        
        print(f"{case['name']:<12} {case['bge']:<8.3f} {case['cross_original']:<12.3f} {cross_normalized:<12.3f} {case['fuzz']:<8.3f} {case['levenshtein']:<12.3f} {weighted_score:<12.3f} {status}")

def test_threshold_analysis():
    """åˆ†æé˜ˆå€¼è®¾ç½®"""
    print("\n" + "=" * 80)
    print("é˜ˆå€¼åˆ†æ")
    print("=" * 80)
    
    service = DisambiguationService()
    
    # åŸºäºå®é™…æµ‹è¯•ç»“æœçš„å¾—åˆ†åˆ†å¸ƒ
    test_scores = [
        ("å®Œå…¨åŒ¹é…", 7.7106),
        ("é«˜ç›¸å…³", 4.9174),
        ("ä¸­ç­‰ç›¸å…³", 3.3470),
        ("ä½ç›¸å…³", 0.1097),
        ("ä¸ç›¸å…³1", -6.5320),
        ("ä¸ç›¸å…³2", -5.4104),
        ("ä¸ç›¸å…³3", -3.3430),
    ]
    
    print("ğŸ“Š å½’ä¸€åŒ–åçš„å¾—åˆ†åˆ†å¸ƒ:")
    print("-" * 50)
    print(f"{'åŒ¹é…ç±»å‹':<12} {'åŸå§‹å¾—åˆ†':<12} {'å½’ä¸€åŒ–å¾—åˆ†':<12} {'å»ºè®®å†³ç­–'}")
    print("-" * 50)
    
    normalized_scores = []
    for match_type, original_score in test_scores:
        normalized_score = service.normalize_crossencoder_score(original_score)
        normalized_scores.append(normalized_score)
        
        # åŸºäºå½’ä¸€åŒ–å¾—åˆ†å»ºè®®å†³ç­–
        if normalized_score > 0.9:
            decision = "åˆå¹¶"
        elif normalized_score > 0.7:
            decision = "å¯èƒ½åˆå¹¶"
        elif normalized_score > 0.3:
            decision = "éœ€è¦å®¡æ ¸"
        else:
            decision = "æ–°å»º"
        
        print(f"{match_type:<12} {original_score:<12.3f} {normalized_score:<12.3f} {decision}")
    
    print("-" * 50)
    
    # åˆ†æé˜ˆå€¼è®¾ç½®
    print(f"\nğŸ¯ é˜ˆå€¼è®¾ç½®å»ºè®®:")
    print(f"  å½“å‰HIGH_THRESHOLD: 0.85")
    print(f"  å½“å‰LOW_THRESHOLD: 0.3")
    
    # è®¡ç®—å»ºè®®é˜ˆå€¼
    sorted_scores = sorted(normalized_scores)
    print(f"\nğŸ“ˆ å¾—åˆ†åˆ†å¸ƒåˆ†æ:")
    print(f"  æœ€é«˜å¾—åˆ†: {max(normalized_scores):.3f}")
    print(f"  æœ€ä½å¾—åˆ†: {min(normalized_scores):.3f}")
    print(f"  ä¸­ä½æ•°: {sorted_scores[len(sorted_scores)//2]:.3f}")
    
    # å»ºè®®é˜ˆå€¼
    high_threshold = 0.85  # ä¿æŒå½“å‰è®¾ç½®
    low_threshold = 0.3    # ä¿æŒå½“å‰è®¾ç½®
    
    print(f"\nğŸ’¡ é˜ˆå€¼å»ºè®®:")
    print(f"  HIGH_THRESHOLD: {high_threshold} (åˆå¹¶é˜ˆå€¼)")
    print(f"  LOW_THRESHOLD: {low_threshold} (æ–°å»ºé˜ˆå€¼)")
    print(f"  æ­§ä¹‰åŒºé—´: [{low_threshold}, {high_threshold}]")

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("=" * 80)
    print("Sigmoidå½’ä¸€åŒ–å…¨é¢æµ‹è¯•")
    print("=" * 80)
    
    # æµ‹è¯•sigmoidå½’ä¸€åŒ–æ•ˆæœ
    normalized_scores = test_sigmoid_normalization()
    
    # æµ‹è¯•ä¿®æ­£åçš„åŠ æƒå¾—åˆ†
    test_weighted_scores()
    
    # åˆ†æé˜ˆå€¼è®¾ç½®
    test_threshold_analysis()
    
    print("\n" + "=" * 80)
    print("æµ‹è¯•æ€»ç»“")
    print("=" * 80)
    
    print("âœ… Sigmoidå½’ä¸€åŒ–ä¿®æ­£å®Œæˆ:")
    print("  1. CrossEncoderå¾—åˆ†å·²ä½¿ç”¨sigmoidå‡½æ•°å½’ä¸€åŒ–")
    print("  2. æ‰€æœ‰å¾—åˆ†éƒ½åœ¨0.0-1.0èŒƒå›´å†…")
    print("  3. åŠ æƒå¾—åˆ†ä¸å†å¼‚å¸¸")
    print("  4. ç³»ç»Ÿè¡Œä¸ºæ›´åŠ ä¸€è‡´")
    
    print("\nğŸ“‹ å®æ–½å†…å®¹:")
    print("  1. æ·»åŠ äº†normalize_crossencoder_scoreå‡½æ•°")
    print("  2. ä¿®æ”¹äº†CrossEncoderå¾—åˆ†è®¡ç®—é€»è¾‘")
    print("  3. æ›´æ–°äº†é…ç½®æ³¨é‡Š")
    print("  4. éªŒè¯äº†å½’ä¸€åŒ–æ•ˆæœ")

if __name__ == "__main__":
    main() 